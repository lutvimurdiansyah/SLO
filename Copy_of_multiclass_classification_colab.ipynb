{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of multiclass_classification_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7xdhY7iQgUSU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lutvimurdiansyah/SLO/blob/main/Copy_of_multiclass_classification_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xdhY7iQgUSU"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTI6TJZfOdZH"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZfzpqO9atfK"
      },
      "source": [
        "# Multiclass Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2265aJc8D5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8pjZcxYWZ8Y"
      },
      "source": [
        "We previously created a binary classification model that determined if a piece of fruit was an orange or a grapefruit. There are many problems where binary classification can provide impactful solutions: spam or not spam in an email classifier, hit or hold in a blackjack simulation, buy or not in a stock market analysis. The list is basically endless.\n",
        "\n",
        "There are other cases, however, where we want to make a decision across three or more classes. This is multiclass classification.\n",
        "\n",
        "For many applications, multiclass classification can be broken down into many binary classification problems. These models employ a one-vs-all or one-vs-one strategy to create many binary classification tasks that are then aggregated into a multiclass classification model. Neural networks, decision trees, and k-nearest neighbors models are all capable of performing multiclass classification directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1cjMb2GPREz"
      },
      "source": [
        "## The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUC2a6L5OqIl"
      },
      "source": [
        "For this unit we are going to use a classic machine learning dataset, the [Iris flower dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set). This is a dataset that was used in 1936 by British biologist and statistician Ronald Fisher to classify iris flowers into one of three species based on four measurements:\n",
        "\n",
        "- The length of the petals\n",
        "- The width of the petals\n",
        "- The length of the sepals (the green petal-looking bits that are found at the base of the petals)\n",
        "- The width of the sepals\n",
        "\n",
        "Conveniently, the iris dataset is built into the scikit-learn library, so it is readily available to us. Let's take a look:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "839qQ8bWalSl"
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "iris_bunch = datasets.load_iris()\n",
        "iris_bunch.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liCmvZznNmoW"
      },
      "source": [
        "iris_bunch['target']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6dLqre2NzLm"
      },
      "source": [
        "iris_bunch['target_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqxVE5XYdXYp"
      },
      "source": [
        "iris_bunch['DESCR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l6qMvU8dipd"
      },
      "source": [
        "iris_bunch['feature_names']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd9-j98xdstc"
      },
      "source": [
        "iris_bunch['filename']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15iEzFlge9V1"
      },
      "source": [
        "iris_bunch['data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zweFHsbUgEUL"
      },
      "source": [
        "Scikit-learn datasets are usually delivered in the form of a dictionary-like object called a `Bunch`. This `Bunch` contains the following fields:\n",
        "\n",
        "- *DESCR*: A string describing the dataset.\n",
        "- *data*: An array containing the features we are using for classifying. In this case, it's the four measurements listed above for each of 150 plants.\n",
        "- *feature_names*: Labels for the data.\n",
        "- *filename*: the file that this data came from.\n",
        "- *target*: the values that we are trying to classify these flowers into. In this case, since we are dealing with three species of iris, we use three numbers (0, 1 and 2) to identify each species.\n",
        "- *target_names*: labels for the target values. In this case, 0 refers to the setosa species, 1 to the versicolor species, and 2 to the virginica species."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqOmZ2ORJhTj"
      },
      "source": [
        "We'll create a list of columns that we'll use for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMqyeotgJoAo"
      },
      "source": [
        "FEATURES = iris_bunch['feature_names']\n",
        "TARGET = 'species'\n",
        "\n",
        "FEATURES, TARGET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQiAihz5DCfP"
      },
      "source": [
        "Next we will load the feature and target data into a Pandas dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4df5QLtC8kK"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris_df = pd.DataFrame(iris_bunch['data'], columns=FEATURES)\n",
        "iris_df[TARGET] = iris_bunch['target']\n",
        "\n",
        "iris_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NjnaQldDJLl"
      },
      "source": [
        "Let's take a look at a description of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNZ2fI-gDWMF"
      },
      "source": [
        "iris_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mEyzlzmDkNR"
      },
      "source": [
        "There are 150 data points. No columns seem to be missing data and no values seem to be too far out of expected ranges. For example, there are no zero or negative lengths or widths, and the length and width values fall well within what we'd expect for a tulip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sOwA2U2EAJs"
      },
      "source": [
        "We are interested in using the measurement features to predict the species of an iris. Let's take a closer look at the values we'll be predicting.\n",
        "\n",
        "In this case we'll group by our 'species' feature and get a count of each species in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPb2c7WZD4P_"
      },
      "source": [
        "iris_df.groupby(TARGET).agg('count')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRzeO3bmcd25"
      },
      "source": [
        "We have 50 examples of each species of iris, and overall we have only 150 samples. This presents two challenges. First, we don't have much data to actually build a model from. Second, the data that we do have is evenly distributed over class types. We might want to make sure that we train over the same distribution.\n",
        "\n",
        "Luckily, there are solutions to both of these issues!\n",
        "\n",
        "When we have data that has some weighted distribution across classes, we can do a **stratified split** to ensure that every class appears proportionally in our training data.\n",
        "\n",
        "When we don't have enough data to properly train a model and don't feel that we can pull training data away, we can do a **k-fold cross validation** in order to utilize all of our data for training, while still trying to minimize model overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viXOR3AseNmB"
      },
      "source": [
        "## Stratified Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE_6f7eMsiW0"
      },
      "source": [
        "Let's first split off a set of data to use for our final model testing. We can use scikit-learn's `train_test_split` function to do this.\n",
        "\n",
        "Since we have so little data, we'll only hold out 10% of the data for the final test.\n",
        "\n",
        "After we make the split, we can see how many data points we will train off of for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9y3IXRaeYPD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_df[FEATURES],\n",
        "    iris_df[TARGET],\n",
        "    test_size=0.1,\n",
        "    random_state=45)\n",
        "\n",
        "y_train.groupby(y_train).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08U3RbJ-vzDn"
      },
      "source": [
        "Yikes! We kept 50 data points for training class 1. That means we left none for final testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtO4hGGCv5rc"
      },
      "source": [
        "y_test.groupby(y_test).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x--twmjowI6D"
      },
      "source": [
        "### Exercise 1: Stratified Train Test Split\n",
        "\n",
        "We risk not holding out a data point for every class if we don't stratify our train test split. Rewrite the split above to create a stratified split. (If you don't remember how, try looking at the [documentation for `train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) and finding the argument that can be used to stratify the data.) When you are done, there should be 45 data points for each class in the training data and five data points for each class in the testing data. Print the counts to verify."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzk1dDO-wrWr"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ1Cf4YMwutU"
      },
      "source": [
        "# Your Code Goes Here\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_df[FEATURES],\n",
        "    iris_df[TARGET],\n",
        "    test_size=0.2,\n",
        "    stratify=iris_df[TARGET])\n",
        "\n",
        "print(y_train.groupby(y_train).count())\n",
        "print(y_test.groupby(y_test).count())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJg9KuFiwv4o"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGLRCakNgXHa"
      },
      "source": [
        "## Cross-Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pjS5qdBxaFJ"
      },
      "source": [
        "Another problem we have is that we have very little data to work with. We only had 150 data points in total and are only going to train using 135 of those data points. If we are going to be hyperparameter tuning, we'll need a test and validation holdout, which will leave us very little data to train on.\n",
        "\n",
        "One way to get around this is to use cross-validation. Cross-validation splits the data into a fixed number of tranches and trains on `n-1` of the tranches. Then it calculates a score using the holdout tranche. It does this repeatedly, holding out one tranche of data for each training pass. By looking at the mean of the scores for each training pass, you can get an idea of how well your model performs without having to specify a test dataset.\n",
        "\n",
        "The `cross_val_score` method is used to perform the cross-validation. In the example below, we divide the data into five tranches and get five scores.\n",
        "\n",
        "Since we are cross-validating with a classifier, scikit-learn automatically performs stratified splits for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWZ97teWgZuk"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "estimator = SGDClassifier()\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iqc-VZMV-2AN"
      },
      "source": [
        "We can now find the mean score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q76bjKa--Vy7"
      },
      "source": [
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTHzxEVW-4bN"
      },
      "source": [
        "What does this score represent, though? It turns out that it uses the default scoring method for the classifier that we used. In this case we used the [`SGDClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html), which reports accuracy by default.\n",
        "\n",
        "Also note that the estimator isn't trained after running cross-validation. You can run cross-validation to test different data preprocessing pipelines and hyperparameters. Once you are happy with a specific setup, you'll need to train the model with the chosen pipeline and parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSikKKbKAWuG"
      },
      "source": [
        "### Exercise 2: F1 Scoring\n",
        "\n",
        "What if we wanted to use F1 for our scoring metric instead of accuracy?\n",
        "\n",
        "Run `cross_val_score` on an `SGDClassifier` and get the F1 score. Check out the documentation for [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), [`make_scorer`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html), and [`f1_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html) for clues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk3hK0WGA5WU"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVC1CiX0A6-A"
      },
      "source": [
        "# Your Code Goes here\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris_bunch = datasets.load_iris()\n",
        "iris_bunch.keys()\n",
        "\n",
        "FEATURES = iris_bunch['feature_names']\n",
        "TARGET = 'species'\n",
        "\n",
        "iris_df = pd.DataFrame(iris_bunch['data'], columns=FEATURES)\n",
        "iris_df[TARGET] = iris_bunch['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    iris_df[FEATURES],\n",
        "    iris_df[TARGET], \n",
        "    test_size=0.1,\n",
        "    stratify=iris_df[TARGET])\n",
        "\n",
        "# Solution Starts Here\n",
        "\n",
        "estimator = SGDClassifier()\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train[FEATURES],\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score, average='micro')\n",
        ")\n",
        "\n",
        "\n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irNxnD-VA8Pb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74WtdKWkBkAj"
      },
      "source": [
        "# The Model Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg-iH2WuCHRd"
      },
      "source": [
        "Since we are now using cross-validation to train the model, we can use our testing holdout data as a final validation. Let's make that clear by renaming the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnwrWu3fCTe5"
      },
      "source": [
        "X_validation = X_test\n",
        "y_validation = y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9juL1rrCfqK"
      },
      "source": [
        "Now we can work on tuning the model and the model pipeline.\n",
        "\n",
        "Let's first look back at the data going into the model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUCG4eT6DOX5"
      },
      "source": [
        "iris_df[FEATURES].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIN9j51JDw-a"
      },
      "source": [
        "The data is all in the same order of magnitude, but columns like 'sepal length (cm)' are considerably larger than columns like 'petal width (cm)'.\n",
        "\n",
        "We need to perform some preprocessing to get the data into a more uniform shape before feeding it to the model. To do that we'll use the [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), which removes the mean and subtracts the unit variance from each column of data.\n",
        "\n",
        "To use the `StandardScaler`, we create the object, `fit()` the data, and then `transform()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdy8I__jDSnY"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(iris_df[FEATURES])\n",
        "\n",
        "pd.DataFrame(\n",
        "    scaler.transform(iris_df[FEATURES]),\n",
        "    columns=FEATURES\n",
        ").describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueBrxZcpEm3C"
      },
      "source": [
        "You can see in the output of `describe()` that the data now all has a standard deviation that approaches one.\n",
        "\n",
        "We need to perform this preprocessing to features before training the model and before getting predictions. It can be error-prone to try to remember to do this. To make the task easier, we can create an estimator [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that applies our transformations and calls our estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl0syxvSFO_c"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['classifier', SGDClassifier()],\n",
        "  ]\n",
        ")\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train[FEATURES],\n",
        "    y_train,\n",
        "    cv=5,\n",
        ")\n",
        "\n",
        "scores.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDkGp3ykFYea"
      },
      "source": [
        "Scaling gave us a considerable jump in accuracy score. Hopefully you see similar results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylEPncqoFgYu"
      },
      "source": [
        "### Exercise 3: Final Validation\n",
        "\n",
        "Our accuracy results were pretty good, so we aren't going to do any more hyperparameter tuning in this lab. Before we declare victory, though, we should find the F1 score of our validation data. Using our estimator pipeline, calculate the F1 score for `X_validation`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxBqABGUFyXv"
      },
      "source": [
        "# Your Code Goes Here\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "iris_bunch = datasets.load_iris()\n",
        "iris_bunch.keys()\n",
        "\n",
        "FEATURES = iris_bunch['feature_names']\n",
        "TARGET = 'species'\n",
        "\n",
        "iris_df = pd.DataFrame(iris_bunch['data'], columns=FEATURES)\n",
        "iris_df[TARGET] = iris_bunch['target']\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(\n",
        "    iris_df[FEATURES],\n",
        "    iris_df[TARGET], \n",
        "    test_size=0.1,\n",
        "    stratify=iris_df[TARGET])\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['classifier', SGDClassifier()],\n",
        "  ]\n",
        ")\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train[FEATURES],\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    # We calculated F1 here too. This isn't required.\n",
        "    scoring=make_scorer(f1_score, average='micro')\n",
        ")\n",
        "\n",
        "# Solution Starts Here\n",
        "estimator.fit(X_train, y_train)\n",
        "predictions = estimator.predict(X_validation)\n",
        "f1_score(y_validation, predictions, average='micro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN0937JcuFmY"
      },
      "source": [
        "#importing confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion = confusion_matrix(y_validation, predictions)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_validation, predictions)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_validation, predictions, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_validation, predictions, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_validation, predictions, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_validation, predictions, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_validation, predictions, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_validation, predictions, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_validation, predictions, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_validation, predictions, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_validation, predictions, average='weighted')))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_validation, predictions, target_names=['Class 1', 'Class 2', 'Class 3']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXoRDEorF0AR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaQgAcKkFWcV"
      },
      "source": [
        "# Exercise 4: Winemaker Identification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9VTg8uUJfwb"
      },
      "source": [
        "Scikit-learn comes prepackaged with many toy datasets. These can be found in the [`sklearn.datasets` package](https://scikit-learn.org/stable/datasets/index.html). In this exercise we'll be working with the [wine dataset](https://scikit-learn.org/stable/datasets/index.html#wine-dataset).\n",
        "\n",
        "The dataset contains information about the properties of wines produced by three different producers. The grapes that the producers used all come from the same region.\n",
        "\n",
        "The columns are:\n",
        "\n",
        "* alcohol\n",
        "* malic_acid\n",
        "* ash\n",
        "* alcalinity_of_ash\n",
        "* magnesium\n",
        "* total_phenols\n",
        "* flavanoids\n",
        "* nonflavanoid_phenols\n",
        "* proanthocyanins\n",
        "* color_intensity\n",
        "* hue\n",
        "* od280/od315_of_diluted_wines\n",
        "* proline\n",
        "\n",
        "The target column is a 0, 1, or 2. Each number represents a different producer.\n",
        "\n",
        "Your task in this exercise is to create a classifier that can identify the producer based on the wine properties.\n",
        "\n",
        "Use as many code blocks as necessary to examine the data and build and validate your model. Document your process using text blocks and/or comments in your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMNL5-jmJHXY"
      },
      "source": [
        "**Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c80bh__Ff3Mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e167b5-86ff-46ef-8207-7d709e26167a"
      },
      "source": [
        "# Your Code Goes Here\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine_bunch = datasets.load_wine()\n",
        "wine_bunch.keys()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzf1QOgmSoU6"
      },
      "source": [
        "\n",
        "FEATURES = wine_bunch['feature_names']\n",
        "TARGET = 'species'\n",
        "\n",
        "wine_df = pd.DataFrame(wine_bunch['data'], columns=FEATURES)\n",
        "wine_df[TARGET] = wine_bunch['target']\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WaJ3dLRSzbF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "7fd30126-ff37-4524-88d7-afe4b566a559"
      },
      "source": [
        "wine_df.head(178)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  species\n",
              "0      14.23        1.71  2.43  ...                          3.92   1065.0        0\n",
              "1      13.20        1.78  2.14  ...                          3.40   1050.0        0\n",
              "2      13.16        2.36  2.67  ...                          3.17   1185.0        0\n",
              "3      14.37        1.95  2.50  ...                          3.45   1480.0        0\n",
              "4      13.24        2.59  2.87  ...                          2.93    735.0        0\n",
              "..       ...         ...   ...  ...                           ...      ...      ...\n",
              "173    13.71        5.65  2.45  ...                          1.74    740.0        2\n",
              "174    13.40        3.91  2.48  ...                          1.56    750.0        2\n",
              "175    13.27        4.28  2.26  ...                          1.56    835.0        2\n",
              "176    13.17        2.59  2.37  ...                          1.62    840.0        2\n",
              "177    14.13        4.10  2.74  ...                          1.60    560.0        2\n",
              "\n",
              "[178 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRYlsiaQYNOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8ea75b-4459-4695-d91a-d848863d852c"
      },
      "source": [
        "wine_bunch['target']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJHBoilPKfTU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu_IQ52YZLQA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb37d70b-26d9-409e-85a2-20c5bdb5ac05"
      },
      "source": [
        "wine_bunch['data']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
              "        1.065e+03],\n",
              "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
              "        1.050e+03],\n",
              "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
              "        1.185e+03],\n",
              "       ...,\n",
              "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
              "        8.350e+02],\n",
              "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
              "        8.400e+02],\n",
              "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
              "        5.600e+02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8q6Rjj1ZRIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "3325a64f-c3e9-4ebb-d4c6-0635fd9021d7"
      },
      "source": [
        "wine_bunch['DESCR']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2kVmthJZVYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06ec1b25-43d4-45d7-da29-239f138b5f34"
      },
      "source": [
        "wine_bunch['feature_names']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alcohol',\n",
              " 'malic_acid',\n",
              " 'ash',\n",
              " 'alcalinity_of_ash',\n",
              " 'magnesium',\n",
              " 'total_phenols',\n",
              " 'flavanoids',\n",
              " 'nonflavanoid_phenols',\n",
              " 'proanthocyanins',\n",
              " 'color_intensity',\n",
              " 'hue',\n",
              " 'od280/od315_of_diluted_wines',\n",
              " 'proline']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3OfOkbyZa12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "b3f2550b-321d-45c6-b416-87a4d7d328fe"
      },
      "source": [
        "wine_df.sample(20)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>13.77</td>\n",
              "      <td>1.90</td>\n",
              "      <td>2.68</td>\n",
              "      <td>17.1</td>\n",
              "      <td>115.0</td>\n",
              "      <td>3.00</td>\n",
              "      <td>2.79</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.68</td>\n",
              "      <td>6.30</td>\n",
              "      <td>1.13</td>\n",
              "      <td>2.93</td>\n",
              "      <td>1375.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>12.43</td>\n",
              "      <td>1.53</td>\n",
              "      <td>2.29</td>\n",
              "      <td>21.5</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2.74</td>\n",
              "      <td>3.15</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.77</td>\n",
              "      <td>3.94</td>\n",
              "      <td>0.69</td>\n",
              "      <td>2.84</td>\n",
              "      <td>352.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>13.82</td>\n",
              "      <td>1.75</td>\n",
              "      <td>2.42</td>\n",
              "      <td>14.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>3.88</td>\n",
              "      <td>3.74</td>\n",
              "      <td>0.32</td>\n",
              "      <td>1.87</td>\n",
              "      <td>7.05</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3.26</td>\n",
              "      <td>1190.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>13.58</td>\n",
              "      <td>1.66</td>\n",
              "      <td>2.36</td>\n",
              "      <td>19.1</td>\n",
              "      <td>106.0</td>\n",
              "      <td>2.86</td>\n",
              "      <td>3.19</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.95</td>\n",
              "      <td>6.90</td>\n",
              "      <td>1.09</td>\n",
              "      <td>2.88</td>\n",
              "      <td>1515.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>12.93</td>\n",
              "      <td>2.81</td>\n",
              "      <td>2.70</td>\n",
              "      <td>21.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>1.54</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.75</td>\n",
              "      <td>4.60</td>\n",
              "      <td>0.77</td>\n",
              "      <td>2.31</td>\n",
              "      <td>600.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>12.64</td>\n",
              "      <td>1.36</td>\n",
              "      <td>2.02</td>\n",
              "      <td>16.8</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.02</td>\n",
              "      <td>1.41</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.62</td>\n",
              "      <td>5.75</td>\n",
              "      <td>0.98</td>\n",
              "      <td>1.59</td>\n",
              "      <td>450.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>13.83</td>\n",
              "      <td>1.57</td>\n",
              "      <td>2.62</td>\n",
              "      <td>20.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>2.95</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1.72</td>\n",
              "      <td>6.60</td>\n",
              "      <td>1.13</td>\n",
              "      <td>2.57</td>\n",
              "      <td>1130.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>12.77</td>\n",
              "      <td>3.43</td>\n",
              "      <td>1.98</td>\n",
              "      <td>16.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.63</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.83</td>\n",
              "      <td>3.40</td>\n",
              "      <td>0.70</td>\n",
              "      <td>2.12</td>\n",
              "      <td>372.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>13.50</td>\n",
              "      <td>1.81</td>\n",
              "      <td>2.61</td>\n",
              "      <td>20.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.53</td>\n",
              "      <td>2.61</td>\n",
              "      <td>0.28</td>\n",
              "      <td>1.66</td>\n",
              "      <td>3.52</td>\n",
              "      <td>1.12</td>\n",
              "      <td>3.82</td>\n",
              "      <td>845.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>12.47</td>\n",
              "      <td>1.52</td>\n",
              "      <td>2.20</td>\n",
              "      <td>19.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2.27</td>\n",
              "      <td>0.32</td>\n",
              "      <td>3.28</td>\n",
              "      <td>2.60</td>\n",
              "      <td>1.16</td>\n",
              "      <td>2.63</td>\n",
              "      <td>937.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>12.33</td>\n",
              "      <td>1.10</td>\n",
              "      <td>2.28</td>\n",
              "      <td>16.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.41</td>\n",
              "      <td>3.27</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.67</td>\n",
              "      <td>680.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>12.36</td>\n",
              "      <td>3.83</td>\n",
              "      <td>2.38</td>\n",
              "      <td>21.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2.30</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.04</td>\n",
              "      <td>7.65</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.58</td>\n",
              "      <td>520.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>11.84</td>\n",
              "      <td>0.89</td>\n",
              "      <td>2.58</td>\n",
              "      <td>18.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>2.20</td>\n",
              "      <td>2.21</td>\n",
              "      <td>0.22</td>\n",
              "      <td>2.35</td>\n",
              "      <td>3.05</td>\n",
              "      <td>0.79</td>\n",
              "      <td>3.08</td>\n",
              "      <td>520.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>13.16</td>\n",
              "      <td>3.57</td>\n",
              "      <td>2.15</td>\n",
              "      <td>21.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.30</td>\n",
              "      <td>4.00</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.68</td>\n",
              "      <td>830.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>12.86</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.32</td>\n",
              "      <td>18.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1.51</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.94</td>\n",
              "      <td>4.10</td>\n",
              "      <td>0.76</td>\n",
              "      <td>1.29</td>\n",
              "      <td>630.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>13.64</td>\n",
              "      <td>3.10</td>\n",
              "      <td>2.56</td>\n",
              "      <td>15.2</td>\n",
              "      <td>116.0</td>\n",
              "      <td>2.70</td>\n",
              "      <td>3.03</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.66</td>\n",
              "      <td>5.10</td>\n",
              "      <td>0.96</td>\n",
              "      <td>3.36</td>\n",
              "      <td>845.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>13.58</td>\n",
              "      <td>2.58</td>\n",
              "      <td>2.69</td>\n",
              "      <td>24.5</td>\n",
              "      <td>105.0</td>\n",
              "      <td>1.55</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.54</td>\n",
              "      <td>8.66</td>\n",
              "      <td>0.74</td>\n",
              "      <td>1.80</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>12.25</td>\n",
              "      <td>1.73</td>\n",
              "      <td>2.12</td>\n",
              "      <td>19.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>2.03</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1.63</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3.17</td>\n",
              "      <td>510.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>13.88</td>\n",
              "      <td>5.04</td>\n",
              "      <td>2.23</td>\n",
              "      <td>20.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.68</td>\n",
              "      <td>4.90</td>\n",
              "      <td>0.58</td>\n",
              "      <td>1.33</td>\n",
              "      <td>415.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  ...  od280/od315_of_diluted_wines  proline  species\n",
              "53     13.77        1.90  2.68  ...                          2.93   1375.0        0\n",
              "126    12.43        1.53  2.29  ...                          2.84    352.0        1\n",
              "52     13.82        1.75  2.42  ...                          3.26   1190.0        0\n",
              "31     13.58        1.66  2.36  ...                          2.88   1515.0        0\n",
              "140    12.93        2.81  2.70  ...                          2.31    600.0        2\n",
              "61     12.64        1.36  2.02  ...                          1.59    450.0        1\n",
              "17     13.83        1.57  2.62  ...                          2.57   1130.0        0\n",
              "118    12.77        3.43  1.98  ...                          2.12    372.0        1\n",
              "24     13.50        1.81  2.61  ...                          3.82    845.0        0\n",
              "95     12.47        1.52  2.20  ...                          2.63    937.0        1\n",
              "60     12.33        1.10  2.28  ...                          1.67    680.0        1\n",
              "160    12.36        3.83  2.38  ...                          1.58    520.0        2\n",
              "84     11.84        0.89  2.58  ...                          3.08    520.0        1\n",
              "145    13.16        3.57  2.15  ...                          1.68    830.0        2\n",
              "130    12.86        1.35  2.32  ...                          1.29    630.0        2\n",
              "19     13.64        3.10  2.56  ...                          3.36    845.0        0\n",
              "168    13.58        2.58  2.69  ...                          1.80    750.0        2\n",
              "106    12.25        1.73  2.12  ...                          3.17    510.0        1\n",
              "146    13.88        5.04  2.23  ...                          1.33    415.0        2\n",
              "174    13.40        3.91  2.48  ...                          1.56    750.0        2\n",
              "\n",
              "[20 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LwONzslaqoC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "7685428b-06bc-435b-e6fa-413a3ab974b5"
      },
      "source": [
        "wine_df.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.000618</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>746.893258</td>\n",
              "      <td>0.938202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.811827</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>314.907474</td>\n",
              "      <td>0.775035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.030000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.362500</td>\n",
              "      <td>1.602500</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.742500</td>\n",
              "      <td>1.205000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>3.220000</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>500.500000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.050000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>2.360000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>2.355000</td>\n",
              "      <td>2.135000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>1.555000</td>\n",
              "      <td>4.690000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>673.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.677500</td>\n",
              "      <td>3.082500</td>\n",
              "      <td>2.557500</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>985.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.830000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1680.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          alcohol  malic_acid  ...      proline     species\n",
              "count  178.000000  178.000000  ...   178.000000  178.000000\n",
              "mean    13.000618    2.336348  ...   746.893258    0.938202\n",
              "std      0.811827    1.117146  ...   314.907474    0.775035\n",
              "min     11.030000    0.740000  ...   278.000000    0.000000\n",
              "25%     12.362500    1.602500  ...   500.500000    0.000000\n",
              "50%     13.050000    1.865000  ...   673.500000    1.000000\n",
              "75%     13.677500    3.082500  ...   985.000000    2.000000\n",
              "max     14.830000    5.800000  ...  1680.000000    2.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjtCPPSQa65k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "1f4b7dde-5cb4-40c5-9782-ba89810cf7de"
      },
      "source": [
        "wine_df.groupby(TARGET).agg('count')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>species</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         alcohol  malic_acid  ash  ...  hue  od280/od315_of_diluted_wines  proline\n",
              "species                            ...                                            \n",
              "0             59          59   59  ...   59                            59       59\n",
              "1             71          71   71  ...   71                            71       71\n",
              "2             48          48   48  ...   48                            48       48\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_nyEicRbWvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc054da1-a10a-4593-ea37-06606461430b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine_df[FEATURES],\n",
        "    wine_df[TARGET],\n",
        "    test_size=0.1,\n",
        "    random_state=40)\n",
        "\n",
        "y_train.groupby(y_train).count()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "species\n",
              "0    53\n",
              "1    64\n",
              "2    43\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsJ2rjVeeWAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615c76c3-1681-4fc3-aadd-a3f8415d0b2c"
      },
      "source": [
        "y_test.groupby(y_test).count()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "species\n",
              "0    6\n",
              "1    7\n",
              "2    5\n",
              "Name: species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMys3U16e0ER",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b3c55a-ec4b-4605-c0ca-889ee307d891"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine_df[FEATURES],\n",
        "    wine_df[TARGET],\n",
        "    test_size=0.2,\n",
        "    stratify=wine_df[TARGET])\n",
        "\n",
        "print(y_train.groupby(y_train).count())\n",
        "print(y_test.groupby(y_test).count())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "species\n",
            "0    47\n",
            "1    57\n",
            "2    38\n",
            "Name: species, dtype: int64\n",
            "species\n",
            "0    12\n",
            "1    14\n",
            "2    10\n",
            "Name: species, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEn4akQVfOLs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5af7c7d3-e782-41b9-ab7c-98bdc0915129"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "estimator = SGDClassifier()\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "scores"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.31034483, 0.5862069 , 0.53571429, 0.53571429, 0.35714286])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02qrVQO9gXDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c98495b-dd3d-4751-8049-d513db65c94f"
      },
      "source": [
        "scores.mean()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4650246305418719"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO2HTrVfhDA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d7fda7-104b-460f-ace7-3c5ebf1cfd99"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "wine_bunch = datasets.load_wine()\n",
        "wine_bunch.keys()\n",
        "\n",
        "FEATURES = wine_bunch['feature_names']\n",
        "TARGET = 'species'\n",
        "\n",
        "wine_df = pd.DataFrame(wine_bunch['data'], columns=FEATURES)\n",
        "wine_df[TARGET] = wine_bunch['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    wine_df[FEATURES],\n",
        "    wine_df[TARGET], \n",
        "    test_size=0.1,\n",
        "    stratify=wine_df[TARGET])\n",
        "\n",
        "# Solution Starts Here\n",
        "\n",
        "estimator = SGDClassifier()\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train[FEATURES],\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=make_scorer(f1_score, average='micro')\n",
        ")\n",
        "\n",
        "\n",
        "scores.mean()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.60625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ESo8aQ7hgDD"
      },
      "source": [
        "X_validation = X_test\n",
        "y_validation = y_test"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwMvDNYJjx2r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "ca7c2dd8-31a5-4bf4-ae07-2be56635eae8"
      },
      "source": [
        "wine_df[FEATURES].describe()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "      <td>178.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>13.000618</td>\n",
              "      <td>2.336348</td>\n",
              "      <td>2.366517</td>\n",
              "      <td>19.494944</td>\n",
              "      <td>99.741573</td>\n",
              "      <td>2.295112</td>\n",
              "      <td>2.029270</td>\n",
              "      <td>0.361854</td>\n",
              "      <td>1.590899</td>\n",
              "      <td>5.058090</td>\n",
              "      <td>0.957449</td>\n",
              "      <td>2.611685</td>\n",
              "      <td>746.893258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.811827</td>\n",
              "      <td>1.117146</td>\n",
              "      <td>0.274344</td>\n",
              "      <td>3.339564</td>\n",
              "      <td>14.282484</td>\n",
              "      <td>0.625851</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>0.124453</td>\n",
              "      <td>0.572359</td>\n",
              "      <td>2.318286</td>\n",
              "      <td>0.228572</td>\n",
              "      <td>0.709990</td>\n",
              "      <td>314.907474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>11.030000</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>10.600000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>0.130000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>0.480000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>278.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>12.362500</td>\n",
              "      <td>1.602500</td>\n",
              "      <td>2.210000</td>\n",
              "      <td>17.200000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>1.742500</td>\n",
              "      <td>1.205000</td>\n",
              "      <td>0.270000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>3.220000</td>\n",
              "      <td>0.782500</td>\n",
              "      <td>1.937500</td>\n",
              "      <td>500.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>13.050000</td>\n",
              "      <td>1.865000</td>\n",
              "      <td>2.360000</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>98.000000</td>\n",
              "      <td>2.355000</td>\n",
              "      <td>2.135000</td>\n",
              "      <td>0.340000</td>\n",
              "      <td>1.555000</td>\n",
              "      <td>4.690000</td>\n",
              "      <td>0.965000</td>\n",
              "      <td>2.780000</td>\n",
              "      <td>673.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>13.677500</td>\n",
              "      <td>3.082500</td>\n",
              "      <td>2.557500</td>\n",
              "      <td>21.500000</td>\n",
              "      <td>107.000000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>2.875000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>1.950000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.120000</td>\n",
              "      <td>3.170000</td>\n",
              "      <td>985.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>14.830000</td>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.230000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>3.880000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.660000</td>\n",
              "      <td>3.580000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1680.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          alcohol  malic_acid  ...  od280/od315_of_diluted_wines      proline\n",
              "count  178.000000  178.000000  ...                    178.000000   178.000000\n",
              "mean    13.000618    2.336348  ...                      2.611685   746.893258\n",
              "std      0.811827    1.117146  ...                      0.709990   314.907474\n",
              "min     11.030000    0.740000  ...                      1.270000   278.000000\n",
              "25%     12.362500    1.602500  ...                      1.937500   500.500000\n",
              "50%     13.050000    1.865000  ...                      2.780000   673.500000\n",
              "75%     13.677500    3.082500  ...                      3.170000   985.000000\n",
              "max     14.830000    5.800000  ...                      4.000000  1680.000000\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACpRiAczj5HQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "25398cc9-4c9d-4b25-974d-dc77580557b1"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(wine_df[FEATURES])\n",
        "\n",
        "pd.DataFrame(\n",
        "    scaler.transform(wine_df[FEATURES]),\n",
        "    columns=FEATURES\n",
        ").describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "      <td>1.780000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.841418e-15</td>\n",
              "      <td>2.444986e-16</td>\n",
              "      <td>-4.059175e-15</td>\n",
              "      <td>-7.110417e-17</td>\n",
              "      <td>-2.494883e-17</td>\n",
              "      <td>-1.955365e-16</td>\n",
              "      <td>9.443133e-16</td>\n",
              "      <td>-4.178929e-16</td>\n",
              "      <td>-1.540590e-15</td>\n",
              "      <td>-4.129032e-16</td>\n",
              "      <td>1.398382e-15</td>\n",
              "      <td>2.126888e-15</td>\n",
              "      <td>-6.985673e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "      <td>1.002821e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.434235e+00</td>\n",
              "      <td>-1.432983e+00</td>\n",
              "      <td>-3.679162e+00</td>\n",
              "      <td>-2.671018e+00</td>\n",
              "      <td>-2.088255e+00</td>\n",
              "      <td>-2.107246e+00</td>\n",
              "      <td>-1.695971e+00</td>\n",
              "      <td>-1.868234e+00</td>\n",
              "      <td>-2.069034e+00</td>\n",
              "      <td>-1.634288e+00</td>\n",
              "      <td>-2.094732e+00</td>\n",
              "      <td>-1.895054e+00</td>\n",
              "      <td>-1.493188e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-7.882448e-01</td>\n",
              "      <td>-6.587486e-01</td>\n",
              "      <td>-5.721225e-01</td>\n",
              "      <td>-6.891372e-01</td>\n",
              "      <td>-8.244151e-01</td>\n",
              "      <td>-8.854682e-01</td>\n",
              "      <td>-8.275393e-01</td>\n",
              "      <td>-7.401412e-01</td>\n",
              "      <td>-5.972835e-01</td>\n",
              "      <td>-7.951025e-01</td>\n",
              "      <td>-7.675624e-01</td>\n",
              "      <td>-9.522483e-01</td>\n",
              "      <td>-7.846378e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>6.099988e-02</td>\n",
              "      <td>-4.231120e-01</td>\n",
              "      <td>-2.382132e-02</td>\n",
              "      <td>1.518295e-03</td>\n",
              "      <td>-1.222817e-01</td>\n",
              "      <td>9.595986e-02</td>\n",
              "      <td>1.061497e-01</td>\n",
              "      <td>-1.760948e-01</td>\n",
              "      <td>-6.289785e-02</td>\n",
              "      <td>-1.592246e-01</td>\n",
              "      <td>3.312687e-02</td>\n",
              "      <td>2.377348e-01</td>\n",
              "      <td>-2.337204e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8.361286e-01</td>\n",
              "      <td>6.697929e-01</td>\n",
              "      <td>6.981085e-01</td>\n",
              "      <td>6.020883e-01</td>\n",
              "      <td>5.096384e-01</td>\n",
              "      <td>8.089974e-01</td>\n",
              "      <td>8.490851e-01</td>\n",
              "      <td>6.095413e-01</td>\n",
              "      <td>6.291754e-01</td>\n",
              "      <td>4.939560e-01</td>\n",
              "      <td>7.131644e-01</td>\n",
              "      <td>7.885875e-01</td>\n",
              "      <td>7.582494e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.259772e+00</td>\n",
              "      <td>3.109192e+00</td>\n",
              "      <td>3.156325e+00</td>\n",
              "      <td>3.154511e+00</td>\n",
              "      <td>4.371372e+00</td>\n",
              "      <td>2.539515e+00</td>\n",
              "      <td>3.062832e+00</td>\n",
              "      <td>2.402403e+00</td>\n",
              "      <td>3.485073e+00</td>\n",
              "      <td>3.435432e+00</td>\n",
              "      <td>3.301694e+00</td>\n",
              "      <td>1.960915e+00</td>\n",
              "      <td>2.971473e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            alcohol    malic_acid  ...  od280/od315_of_diluted_wines       proline\n",
              "count  1.780000e+02  1.780000e+02  ...                  1.780000e+02  1.780000e+02\n",
              "mean   7.841418e-15  2.444986e-16  ...                  2.126888e-15 -6.985673e-17\n",
              "std    1.002821e+00  1.002821e+00  ...                  1.002821e+00  1.002821e+00\n",
              "min   -2.434235e+00 -1.432983e+00  ...                 -1.895054e+00 -1.493188e+00\n",
              "25%   -7.882448e-01 -6.587486e-01  ...                 -9.522483e-01 -7.846378e-01\n",
              "50%    6.099988e-02 -4.231120e-01  ...                  2.377348e-01 -2.337204e-01\n",
              "75%    8.361286e-01  6.697929e-01  ...                  7.885875e-01  7.582494e-01\n",
              "max    2.259772e+00  3.109192e+00  ...                  1.960915e+00  2.971473e+00\n",
              "\n",
              "[8 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3PGGICQkCcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906dd615-ca4b-459c-b29f-0ffdb2ef4251"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['classifier', SGDClassifier()],\n",
        "  ]\n",
        ")\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train[FEATURES],\n",
        "    y_train,\n",
        "    cv=5,\n",
        ")\n",
        "\n",
        "scores.mean()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lDsRDqglZL8",
        "outputId": "91ab0f3a-ddd5-4a84-8232-e2964dcb70b3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "wine_bunch = datasets.load_iris()\n",
        "wine_bunch.keys()\n",
        "\n",
        "FEATURES = wine_bunch['feature_names']\n",
        "TARGET = 'species'\n",
        "\n",
        "wine_df = pd.DataFrame(wine_bunch['data'], columns=FEATURES)\n",
        "wine_df[TARGET] = wine_bunch['target']\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(\n",
        "    wine_df[FEATURES],\n",
        "    wine_df[TARGET], \n",
        "    test_size=0.1,\n",
        "    stratify=wine_df[TARGET])\n",
        "\n",
        "estimator = Pipeline(\n",
        "  steps=[\n",
        "    ['scale', StandardScaler()],\n",
        "    ['classifier', SGDClassifier()],\n",
        "  ]\n",
        ")\n",
        "\n",
        "scores = cross_val_score(\n",
        "    estimator,\n",
        "    X_train[FEATURES],\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    # We calculated F1 here too. This isn't required.\n",
        "    scoring=make_scorer(f1_score, average='micro')\n",
        ")\n",
        "\n",
        "# Solution Starts Here\n",
        "estimator.fit(X_train, y_train)\n",
        "predictions = estimator.predict(X_validation)\n",
        "f1_score(y_validation, predictions, average='micro')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQgFAVNRlueo",
        "outputId": "94fed866-7969-4690-99a3-c8d8ae0df08b"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion = confusion_matrix(y_validation, predictions)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "\n",
        "#importing accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('\\nAccuracy: {:.2f}\\n'.format(accuracy_score(y_validation, predictions)))\n",
        "\n",
        "print('Micro Precision: {:.2f}'.format(precision_score(y_validation, predictions, average='micro')))\n",
        "print('Micro Recall: {:.2f}'.format(recall_score(y_validation, predictions, average='micro')))\n",
        "print('Micro F1-score: {:.2f}\\n'.format(f1_score(y_validation, predictions, average='micro')))\n",
        "\n",
        "print('Macro Precision: {:.2f}'.format(precision_score(y_validation, predictions, average='macro')))\n",
        "print('Macro Recall: {:.2f}'.format(recall_score(y_validation, predictions, average='macro')))\n",
        "print('Macro F1-score: {:.2f}\\n'.format(f1_score(y_validation, predictions, average='macro')))\n",
        "\n",
        "print('Weighted Precision: {:.2f}'.format(precision_score(y_validation, predictions, average='weighted')))\n",
        "print('Weighted Recall: {:.2f}'.format(recall_score(y_validation, predictions, average='weighted')))\n",
        "print('Weighted F1-score: {:.2f}'.format(f1_score(y_validation, predictions, average='weighted')))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('\\nClassification Report\\n')\n",
        "print(classification_report(y_validation, predictions, target_names=['Class 1', 'Class 2', 'Class 3']))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[5 0 0]\n",
            " [1 3 1]\n",
            " [0 0 5]]\n",
            "\n",
            "Accuracy: 0.87\n",
            "\n",
            "Micro Precision: 0.87\n",
            "Micro Recall: 0.87\n",
            "Micro F1-score: 0.87\n",
            "\n",
            "Macro Precision: 0.89\n",
            "Macro Recall: 0.87\n",
            "Macro F1-score: 0.86\n",
            "\n",
            "Weighted Precision: 0.89\n",
            "Weighted Recall: 0.87\n",
            "Weighted F1-score: 0.86\n",
            "\n",
            "Classification Report\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 1       0.83      1.00      0.91         5\n",
            "     Class 2       1.00      0.60      0.75         5\n",
            "     Class 3       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.87        15\n",
            "   macro avg       0.89      0.87      0.86        15\n",
            "weighted avg       0.89      0.87      0.86        15\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}